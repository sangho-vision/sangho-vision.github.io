---
layout: default
---

Hello! I am a Postdoctoral Young Investigator at AI2 on the PRIOR team, based in Seattle, WA.


My academic interests lie in computer vision, machine learning and their applications to real world problems.
Specifically, I focus on multimodal representation learning, especially for high-level video understanding and reasoning.
Prior to joining AI2, I received my Ph.D. in Computer Science and Engineering from Seoul National University where I was advised by [Prof. Gunhee Kim](http://vision.snu.ac.kr/~gunhee/).

### Education

<h4 class="education">
  <i class="material-icons md-18">work</i>
  <a href="https://allenai.org/">Allen Institute for AI</a>, Seattle, WA, USA
  <sup>2023.01 - Current</sup>
</h4>

- Postdoctoral Young Investigator on the [PRIOR] team

<h4 class="education">
  <i class="material-icons md-18">school</i>
  <a href="http://en.snu.ac.kr/">Seoul National University (SNU)</a>, Seoul, South Korea
  <sup>2017.03 - 2023.02</sup>
</h4>

- Ph.D. in [Computer Science and Engineering]
- Advisor: [Prof. Gunhee Kim](http://vision.snu.ac.kr/~gunhee/)
- Thesis: Improving Efficiency in Large-Scale Self-Supervised Video Representation Learning

<h4 class="education">
  <i class="material-icons md-18">school</i>
  <a href="http://en.snu.ac.kr/">Seoul National University (SNU)</a>, Seoul, South Korea
  <sup>2010.03 - 2017.02</sup>
</h4>

- B.S. in [Computer Science and Engineering] (minor in [Statistics])

[PRIOR]: https://prior.allenai.org/
[Computer Science and Engineering]: https://cse.snu.ac.kr/en
[Statistics]: https://stat.snu.ac.kr/eng/

### Publications

- Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action <br/>
Jiasen Lu\*, Christopher Clark\*, **Sangho Lee**\*, Zichen Zhang\*, Savya Khosla, Ryan Marten, Derek Hoiem, Aniruddha Kembhavi (\*: equal contribution) <br/>
CVPR 2024 <br/>
<a class="code" href="https://arxiv.org/abs/2312.17172">[paper]</a>
<a class="code" href="https://unified-io-2.allenai.org">[webpage]</a>

- Can Language Models Laugh at YouTube Short-form Videos? <br/>
Dayoon Ko, **Sangho Lee** and Gunhee Kim <br/>
EMNLP 2023 <br/>
<a class="code" href="https://arxiv.org/abs/2310.14159">[paper]</a>
<a class="code" href="https://github.com/dayoon-ko/ExFunTube">[code&dataset]</a>

- ACAV100M: Automatic Curation of Large-Scale Datasets for Audio-Visual Video Representation Learning <br/>
**Sangho Lee**\*, Jiwan Chung\*, Youngjae Yu, Gunhee Kim, Thomas Breuel, Gal Chechik and Yale Song (\*: equal contribution) <br/>
ICCV 2021 <br/>
CVPR 2021: The Third Workshop on Learning from Unlabeled Videos <br/>
<a class="code" href="https://arxiv.org/abs/2101.10803">[paper]</a>
<a class="code" href="https://acav100m.github.io">[code&dataset]</a>

- Unsupervised Representation Learning via Neural Activation Coding <br/>
Yookoon Park, **Sangho Lee**, Gunhee Kim and David Blei <br/>
ICML 2021 (long talk) <br/>
<a class="code" href="http://proceedings.mlr.press/v139/park21b.html">[paper]</a>
<a class="code" href="assets/poster/icml21_park_poster.png">[poster]</a>
<a class="code" href="assets/slides/icml21_park_slides.pdf">[slides]</a>
<a class="code" href="https://github.com/yookoon/nac">[code]</a>

- Parameter Efficient Multimodal Transformers for Video Representation Learning <br/>
**Sangho Lee**, Youngjae Yu, Gunhee Kim, Thomas Breuel, Jan Kautz and Yale Song <br/>
ICLR 2021 <br/>
CVPR 2021: The Second Intertional Workshop on Large Scale Holistic Video Understanding <br/>
<a class="code" href="https://openreview.net/forum?id=6UdQLhqJyFD">[paper]</a>
<a class="code" href="assets/poster/iclr2021_lee_poster.png">[poster]</a>
<a class="code" href="assets/slides/iclr2021_lee_slides.pdf">[slides]</a>

- Self-Supervised Learning of Compressed Video Representations <br/>
Youngjae Yu\*, **Sangho Lee**\*, Gunhee Kim and Yale Song (\*: equal contribution) <br/>
ICLR 2021 <br/>
<a class="code" href="https://openreview.net/forum?id=jMPcEkJpdD">[paper]</a>
<a class="code" href="assets/poster/iclr2021_yu_poster.png">[poster]</a>
<a class="code" href="assets/slides/iclr2021_yu_slides.pdf">[slides]</a>

- A Memory Network Approach for Story-based Temporal Summarization of 360&deg; Videos <br/>
**Sangho Lee**, Jinyoung Sung, Youngjae Yu and Gunhee Kim <br/>
CVPR 2018 <br/>
ECCV 2018 Workshop on 360&deg; Perception and Interaction <br/>
<a class="code" href="https://arxiv.org/abs/1805.02838">[paper]</a>
<a class="code" href="http://vision.snu.ac.kr/projects/pfmn/">[project page (poster/slides/bibtex)]</a>

- A Deep Ranking Model for Spatio-temporal Highlight Detection from a 360&deg; Video <br/>
Youngjae Yu, **Sangho Lee**, Joonil Na, Jaeyoun Kang and Gunhee Kim <br/>
AAAI 2018 (spotlight) <br/>
<a class="code" href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17213"> [paper]</a>
<a class="code" href="assets/poster/aaai_vrsumm_poster.pdf"> [poster]</a>
<a class="code" href="assets/slides/aaai_vrsumm_spotlight_2page.pdf"> [slides]</a>
<a class="code" href="assets/bibtex/aaai18_cvs.txt">[bibtex]</a>

- A Read-Write Memory Network for Movie Story Understanding <br/>
Seil Na, **Sangho Lee**, Jisung Kim and Gunhee Kim <br/>
ICCV 2017 <br/>
ICCV 2017: The Joint Video and Language Understanding Workshop <br/>
<a class="code" href="https://arxiv.org/abs/1709.09345">[paper]</a>
<a class="code" href="https://github.com/seilna/RWMN">[code]</a>
<a class="code" href="assets/poster/iccv17_movieqa_poster.pdf">[poster]</a>
<a class="code" href="assets/bibtex/iccv17_movieqa.txt">[bibtex]</a>

- Encoding Video and Label Priors for Multi-label Video Classification on YouTube-8M dataset <br/>
Seil Na, Youngjae Yu, **Sangho Lee**, Jisung Kim and Gunhee Kim <br/>
CVPR 2017 Workshop on YouTube-8M Large-Scale Video Understanding <br/>
<a class="code" href="https://arxiv.org/abs/1706.07960">[paper]</a>
<a class="code" href="https://github.com/seilna/youtube8m">[code]</a>
<a class="code" href="assets/bibtex/cvpr_workshop_2017_video.txt">[bibtex]</a>


### Work Experience

- [PRIOR @ Allen Institute for AI](https://prior.allenai.org/) Research Intern (March-June, August-December 2022)


### Awards
- [Excellent Ph.D. Thesis Award](https://sangho-vision.github.io/) (SNU CSE, 2023)
  - Selected as the best doctoral thesis by Department of Computer Science and Engineering, Seoul National University
- [Naver Ph.D. Fellowship](https://sangho-vision.github.io/) (Naver, 2021)
  - Awarded to outstanding graduate students in the field of Computer Science for their exceptional academic research
- [Youlchon AI Star Fellowship](https://aiis.snu.ac.kr/bbs/board.php?bo_table=eng4_3) (Youlchon Foundation, Nongshim Group, 2021)
  - An award for those who made distinguished research achievements in core AI fields
- [MovieQA Challenge @ ICCV 2017 Workshop](https://www.rsipvision.com/ICCV2017-Wednesday/) (ICCV Workshop, 2017)
  - ICCV 2017 Workshop on the Joining Video and Language Understanding
  - Ranked 2nd place
- [Google Cloud & YouTube-8M Video Understanding Challenge](https://www.kaggle.com/c/youtube8m/leaderboard) (CVPR Workshop, 2017)
  - CVPR 2017 Workshop on YouTube-8M Large-Scale Video Understanding
  - Ranked 8th place out of 655 teams (Top 2%)
